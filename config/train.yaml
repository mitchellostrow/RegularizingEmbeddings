# Wandb configuration
wandb:
  project: "sequence_model"
  name: ${now:%Y-%m-%d_%H-%M-%S}

# Training configuration
training:
  max_epochs: 100
  patience: 10
  accelerator: "auto"
  devices: 1
  gradient_clip_val: 1.0

# Data configuration
data:
  batch_size: 32
  num_workers: 4
  pin_memory: True
  datasets: ??? # To be filled with actual datasets

# Model configuration
model:
  _target_: src.models.your_model.YourModel
  hidden_size: 256
  # other model parameters...

# Optimizer configuration
optimizer:
  _target_: torch.optim.Adam
  lr: 0.001

# Learning rate scheduler configuration
scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  mode: min
  factor: 0.1
  patience: 5

# Loss function configuration
criterion:
  _target_: torch.nn.MSELoss

# Paths configuration
paths:
  output_dir: ${hydra:runtime.output_dir} 