{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from RegularizingEmbeddings.lightning.model import SequenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcb654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 14:52:50.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mRegularizingEmbeddings.lightning.model\u001b[0m:\u001b[36minit_criterion\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mRegularization lambda: 0.0010000000474974513, regularization: TanglingRegularization\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"outputs/sample.ckpt\"\n",
    "model = SequenceModel.load_from_checkpoint(checkpoint_path).model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12642b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 13.7515,   9.2614,  31.0919]],\n",
      "\n",
      "        [[ -3.1054,   6.6575,  15.5631]],\n",
      "\n",
      "        [[  0.1806,  -0.5161,   4.8349]],\n",
      "\n",
      "        [[-15.1073,  -0.6552,  33.9413]],\n",
      "\n",
      "        [[  6.1447,   7.9746,  18.0374]],\n",
      "\n",
      "        [[  6.7847,  -6.9916,   8.3878]],\n",
      "\n",
      "        [[ -6.0293,  13.1938,  16.7763]],\n",
      "\n",
      "        [[-16.5259,  11.0976,  40.3096]],\n",
      "\n",
      "        [[ -2.1407,  -0.4861,  17.1341]],\n",
      "\n",
      "        [[ -3.2916,   6.5715,  28.4211]],\n",
      "\n",
      "        [[ 30.9921,  14.2830,  49.5011]],\n",
      "\n",
      "        [[  9.5022,   7.0349,  26.8920]],\n",
      "\n",
      "        [[ -4.4191,  14.1883,  13.2847]],\n",
      "\n",
      "        [[ -4.8348,   6.6681,  28.4937]],\n",
      "\n",
      "        [[  1.9114,   6.3659,  12.6940]],\n",
      "\n",
      "        [[-12.0892,  12.0604,  24.6646]],\n",
      "\n",
      "        [[  1.5625,   1.1036,   8.5594]],\n",
      "\n",
      "        [[ 24.5712,  17.3881,  43.9023]],\n",
      "\n",
      "        [[ -9.0404,   9.8439,  22.3861]],\n",
      "\n",
      "        [[  9.3375,  15.3377,  11.5489]],\n",
      "\n",
      "        [[ -7.5587,  11.0744,  20.0466]],\n",
      "\n",
      "        [[ 18.5913,   8.5199,  35.5090]],\n",
      "\n",
      "        [[ 13.1806,  -0.0882,  10.4591]],\n",
      "\n",
      "        [[  0.8308,   0.8477,   9.7340]],\n",
      "\n",
      "        [[ 12.9202,  12.7152,  25.5860]],\n",
      "\n",
      "        [[ 14.5669,  -3.9447,  26.1394]],\n",
      "\n",
      "        [[ -2.6797,  10.3613,  18.4531]],\n",
      "\n",
      "        [[ -3.8189,   8.2106,  20.9612]],\n",
      "\n",
      "        [[ 12.4138,  11.9517,  27.9983]],\n",
      "\n",
      "        [[ -2.3799,   4.8050,  25.2224]],\n",
      "\n",
      "        [[-18.6710,   1.6974,  41.5469]],\n",
      "\n",
      "        [[ -0.8720,   7.4956,  11.0204]],\n",
      "\n",
      "        [[ 19.5670,   0.6156,  23.8086]],\n",
      "\n",
      "        [[  2.6776,   1.8835,   2.7212]],\n",
      "\n",
      "        [[  1.6446,  -4.8542,   2.5609]],\n",
      "\n",
      "        [[ -2.6708,   0.4932,   5.4776]],\n",
      "\n",
      "        [[-13.5774,   6.5295,  32.0188]],\n",
      "\n",
      "        [[ 14.2000,  -1.2761,   9.6486]],\n",
      "\n",
      "        [[ -2.1832,   6.6579,  21.6426]],\n",
      "\n",
      "        [[ -1.8592,   5.5293,  25.8742]],\n",
      "\n",
      "        [[ -4.8083,  11.4434,  14.2729]],\n",
      "\n",
      "        [[  0.0588,  10.2633,  10.0469]],\n",
      "\n",
      "        [[ 33.4263,   7.2366,  52.2655]],\n",
      "\n",
      "        [[ -4.5329,   8.4134,  17.4738]],\n",
      "\n",
      "        [[ 19.8431,  -2.1389,  33.2068]],\n",
      "\n",
      "        [[ 24.1187,   6.1052,  45.6510]],\n",
      "\n",
      "        [[-13.1931,  -2.3664,  24.9372]],\n",
      "\n",
      "        [[ 24.9093,   8.5988,  29.6165]],\n",
      "\n",
      "        [[  7.3174,  -6.0157,  11.3916]],\n",
      "\n",
      "        [[ -5.7409,   2.4789,  15.3406]]], device='mps:0',\n",
      "       grad_fn=<LinearBackward0>), tensor([[[ -52.0737-253.4793j, -229.4324-88.3257j,  146.1492-166.3468j,\n",
      "           ...,  -18.7365-13.7622j,   -1.2462-11.3875j,\n",
      "          -588.9246-148.8550j]],\n",
      "\n",
      "        [[-316.4772-323.9307j, -169.9263+278.0088j,   27.1885-145.3322j,\n",
      "           ...,  -48.1519+3.6786j,  -24.8023+8.2451j,\n",
      "          -197.7033-276.3500j]],\n",
      "\n",
      "        [[ -78.3933-112.3049j,   99.9785-80.3434j,   22.0064-232.2631j,\n",
      "           ...,  -34.7501-13.6660j,  -19.3390+1.3727j,\n",
      "          -613.2955-57.6123j]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -45.4078-148.6424j, -154.3152-200.5603j,   96.9466-208.6745j,\n",
      "           ...,  -30.9639-8.0629j,  -15.3813+3.2452j,\n",
      "          -613.2236-84.5378j]],\n",
      "\n",
      "        [[ 293.8455+214.1108j,  454.5502-432.2799j,   -3.1078-182.6410j,\n",
      "           ...,   13.8753-34.3772j,    8.0214-19.2043j,\n",
      "          -765.3889+260.9551j]],\n",
      "\n",
      "        [[-174.3051-117.0255j,  234.0821+109.7529j,  -51.6399-218.8222j,\n",
      "           ...,  -42.6770-10.5117j,  -26.4398+5.3460j,\n",
      "          -445.9510-85.7670j]]], device='mps:0', grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# Input a random torch array to the model\n",
    "device = next(model.parameters()).device  # get model device (e.g., 'mps', 'cuda', 'cpu')\n",
    "input_tensor = torch.randn(50, 3, device=device)\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99ca44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdq219\u001b[0m (\u001b[33mdq219-massachusetts-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 3ksd71dg\n",
      "Name: 2025-08-27_13-50-13\n",
      "State: crashed\n",
      "Created at: 2025-08-27T17:50:18Z\n",
      "Summary: {'_runtime': 572.87894114, '_step': 289, '_timestamp': 1756317595.7470531, '_wandb': {'runtime': 572}, 'epoch': 72, 'train_loss_epoch': 1.5024938583374023, 'train_loss_step': 1.130514144897461, 'train_reg_loss_epoch': 2.86093581962632e-05, 'train_reg_loss_step': 3.369941987330094e-05, 'train_total_loss_epoch': 1.5025224685668943, 'train_total_loss_step': 1.1305478811264038, 'trainer/global_step': 7299, 'val_loss': 0.16228684782981873, 'val_reg_loss': 7.807563633832615e-06, 'val_total_loss': 0.1622946411371231}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'rmax': 0.99, 'rmin': 0.8, 'siso': False, 'd_model': 64, 'd_state': 32, 'dropout': 0.1, '_target_': 'RegularizingEmbeddings.models.lru.LRUMinimal', 'input_dim': None, 'mlp_hidden': 64}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 1, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.lru.LRUMinimal', 'input_dim': 3, 'd_model': 64, 'd_state': 32, 'mlp_hidden': 64, 'siso': False, 'rmin': 0.8, 'rmax': 0.99, 'dropout': 0.1}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'n_neighbors': 10, 'max_T': 5, 'normalize': True, 'epsilon': 1e-10, 'dt': 0.0075071279699874946}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_13-50-13', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 1}, 'regularization': {'dt': 1e-06, 'max_T': 5, 'epsilon': 1e-10, '_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'normalize': True, 'n_neighbors': 10}}\n",
      "----------------------------------------\n",
      "Run ID: bci10hjq\n",
      "Name: 2025-08-27_13-58-08\n",
      "State: crashed\n",
      "Created at: 2025-08-27T17:58:15Z\n",
      "Summary: {'_runtime': 123.358824693, '_step': 20, '_timestamp': 1756317619.4002433, '_wandb': {'runtime': 123}, 'epoch': 5, 'train_loss_epoch': 26.594667434692383, 'train_loss_step': 22.318845748901367, 'train_reg_loss_epoch': 0.04871262609958649, 'train_reg_loss_step': 0.048306193202733994, 'train_total_loss_epoch': 26.643369674682617, 'train_total_loss_step': 22.367151260375977, 'trainer/global_step': 549, 'val_loss': 23.336679458618164, 'val_reg_loss': 0.0015492259990423918, 'val_total_loss': 23.33823013305664}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'d_model': 10, '_target_': 'RegularizingEmbeddings.models.delayed_mlp.DelayedMLP', 'input_dim': 1, 'mlp_hidden': 50, 'delay_interval': 1}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 1, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.delayed_mlp.DelayedMLP', 'input_dim': 3, 'mlp_hidden': 50, 'd_model': 10, 'delay_interval': 1}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'n_neighbors': 10, 'max_T': 5, 'normalize': True, 'epsilon': 1e-10, 'dt': 0.0075071279699874946}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_13-58-08', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 1}, 'regularization': {'dt': 1e-06, 'max_T': 5, 'epsilon': 1e-10, '_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'normalize': True, 'n_neighbors': 10}}\n",
      "----------------------------------------\n",
      "Run ID: 7w1jirv9\n",
      "Name: 2025-08-27_14-04-04\n",
      "State: finished\n",
      "Created at: 2025-08-27T18:04:08Z\n",
      "Summary: {'_runtime': 165, '_wandb': {'runtime': 165}}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'noC': False, 'seed': 10, 'd_model': 1, 'd_state': 50, 'dropout': 0, 'prenorm': True, '_target_': 'RegularizingEmbeddings.models.s4.S4DMinimal', 'input_dim': 1, 'mlp_hidden': None}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 1, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.s4.S4DMinimal', 'input_dim': 3, 'd_model': 1, 'd_state': 50, 'dropout': 0.0, 'prenorm': True, 'mlp_hidden': None, 'noC': False, 'seed': 10}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'n_neighbors': 10, 'max_T': 5, 'normalize': True, 'epsilon': 1e-10, 'dt': 0.0075071279699874946}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_14-04-04', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 1}, 'regularization': {'dt': 1e-06, 'max_T': 5, 'epsilon': 1e-10, '_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'normalize': True, 'n_neighbors': 10}}\n",
      "----------------------------------------\n",
      "Run ID: oiq8bjpm\n",
      "Name: 2025-08-27_14-07-20\n",
      "State: finished\n",
      "Created at: 2025-08-27T18:07:24Z\n",
      "Summary: {'_runtime': 134, '_wandb': {'runtime': 134}}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'seed': 10, 'd_model': 50, 'dropout': 0, '_target_': 'RegularizingEmbeddings.models.rnns.RNNBase', 'input_dim': 1, 'activation': 'relu', 'architecture': 'VanillaRNN'}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 1, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.rnns.RNNBase', 'input_dim': 3, 'architecture': 'VanillaRNN', 'd_model': 50, 'activation': 'relu', 'dropout': 0.0, 'seed': 10}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'n_neighbors': 10, 'max_T': 5, 'normalize': True, 'epsilon': 1e-10, 'dt': 0.0075071279699874946}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_14-07-20', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 1}, 'regularization': {'dt': 1e-06, 'max_T': 5, 'epsilon': 1e-10, '_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'normalize': True, 'n_neighbors': 10}}\n",
      "----------------------------------------\n",
      "Run ID: 9i2ohpmh\n",
      "Name: 2025-08-27_14-09-47\n",
      "State: finished\n",
      "Created at: 2025-08-27T18:09:50Z\n",
      "Summary: {'_runtime': 103, '_step': 55, '_timestamp': 1756318267.0189712, '_wandb': {'runtime': 103}, 'epoch': 13, 'train_loss_epoch': 7.071044445037842, 'train_loss_step': 7.290563106536865, 'train_reg_loss_epoch': 0.00927624385803938, 'train_reg_loss_step': 0.009143339470028876, 'train_total_loss_epoch': 7.080319881439209, 'train_total_loss_step': 7.29970645904541, 'trainer/global_step': 1399, 'val_loss': 6.690556049346924, 'val_reg_loss': 0.0005991762154735625, 'val_total_loss': 6.691156387329102}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'seed': 10, 'd_model': 50, 'dropout': 0, '_target_': 'RegularizingEmbeddings.models.rnns.RNNBase', 'input_dim': 1, 'activation': 'relu', 'architecture': 'VanillaRNN'}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 1, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.rnns.RNNBase', 'input_dim': 3, 'architecture': 'VanillaRNN', 'd_model': 50, 'activation': 'relu', 'dropout': 0.0, 'seed': 10}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'n_neighbors': 10, 'max_T': 5, 'normalize': True, 'epsilon': 1e-10, 'dt': 0.0075071279699874946}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_14-09-47', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 1}, 'regularization': {'dt': 1e-06, 'max_T': 5, 'epsilon': 1e-10, '_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'normalize': True, 'n_neighbors': 10}}\n",
      "----------------------------------------\n",
      "Run ID: euh727gs\n",
      "Name: 2025-08-27_14-11-47\n",
      "State: finished\n",
      "Created at: 2025-08-27T18:11:50Z\n",
      "Summary: {'_runtime': 343, '_wandb': {'runtime': 343}}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'d_model': 10, 'd_state': 10, 'dt_rank': 10, '_target_': 'RegularizingEmbeddings.models.mamba.MinimalMamba', 'input_dim': 1}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 1, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.mamba.MinimalMamba', 'd_model': 10, 'input_dim': 3, 'dt_rank': 10, 'd_state': 10}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'n_neighbors': 10, 'max_T': 5, 'normalize': True, 'epsilon': 1e-10, 'dt': 0.0075071279699874946}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_14-11-47', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 1}, 'regularization': {'dt': 1e-06, 'max_T': 5, 'epsilon': 1e-10, '_target_': 'RegularizingEmbeddings.regularization.amplification.AmplificationRegularization', 'normalize': True, 'n_neighbors': 10}}\n",
      "----------------------------------------\n",
      "Run ID: epxx9r3b\n",
      "Name: 2025-08-27_14-18-00\n",
      "State: finished\n",
      "Created at: 2025-08-27T18:18:03Z\n",
      "Summary: {'_runtime': 102, '_step': 4, '_timestamp': 1756318777.2805138, '_wandb': {'runtime': 102}, 'epoch': 1, 'train_loss_epoch': 237.64898681640625, 'train_loss_step': 186.54351806640625, 'train_reg_loss_epoch': 43734.40625, 'train_reg_loss_step': 32383.25, 'train_total_loss_epoch': 43972.05078125, 'train_total_loss_step': 32569.79296875, 'trainer/global_step': 149, 'val_loss': 214.6484375, 'val_reg_loss': 40964.4921875, 'val_total_loss': 41179.1484375}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'rmax': 0.99, 'rmin': 0.8, 'siso': False, 'd_model': 64, 'd_state': 32, 'dropout': 0.1, '_target_': 'RegularizingEmbeddings.models.lru.LRUMinimal', 'input_dim': None, 'mlp_hidden': 64}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 1, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.lru.LRUMinimal', 'input_dim': 3, 'd_model': 64, 'd_state': 32, 'mlp_hidden': 64, 'siso': False, 'rmin': 0.8, 'rmax': 0.99, 'dropout': 0.1}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.tangling.TanglingRegularization', 'mode': 'efficient', 'epsilon': 1e-06, 'dt': 0.0075071279699874946, 'normalize': True}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_14-18-00', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 1}, 'regularization': {'dt': 1e-06, 'mode': 'efficient', 'epsilon': 1e-06, '_target_': 'RegularizingEmbeddings.regularization.tangling.TanglingRegularization', 'normalize': True}}\n",
      "----------------------------------------\n",
      "Run ID: zr59lpcm\n",
      "Name: 2025-08-27_14-20-00\n",
      "State: finished\n",
      "Created at: 2025-08-27T18:20:03Z\n",
      "Summary: {'_runtime': 693, '_step': 44, '_timestamp': 1756319493.4411347, '_wandb': {'runtime': 693}, 'epoch': 11, 'train_loss_epoch': 30.13536834716797, 'train_loss_step': 27.638742446899418, 'train_reg_loss_epoch': 24018.33203125, 'train_reg_loss_step': 24073.84765625, 'train_total_loss_epoch': 54.15370178222656, 'train_total_loss_step': 51.71259307861328, 'trainer/global_step': 1149, 'val_loss': 23.804990768432617, 'val_reg_loss': 29594.447265625, 'val_total_loss': 53.399436950683594}\n",
      "Config: {'data': {'flow': {'dt': None, '_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42}, 'postprocessing': {'low_pass': 10, 'high_pass': None, 'obs_noise': 0, 'filter_data': False, 'dims_to_observe': 'all'}, 'train_test_params': {'dtype': 'torch.FloatTensor', 'verbose': True, 'split_by': 'trajectory', 'seq_length': 25, 'seq_spacing': 1, 'test_percent': 0.1, 'train_percent': 0.7, 'delay_embedding_params': {'n_delays': 1, 'delay_spacing': 1, 'observed_indices': 'all'}}, 'trajectory_params': {'noise': 0, 'method': 'Radau', 'num_ics': 20, 'verbose': True, 'resample': True, 'n_periods': 12, 'new_ic_mode': 'reference', 'standardize': False, 'return_times': True, 'pts_per_period': 200, 'traj_offset_sd': 0.01}}, 'model': {'rmax': 0.99, 'rmin': 0.8, 'siso': False, 'd_model': 64, 'd_state': 32, 'dropout': 0.1, '_target_': 'RegularizingEmbeddings.models.lru.LRUMinimal', 'input_dim': None, 'mlp_hidden': 64}, 'config': \"{'training': {'wandb': {'project': 'regularizing-embeddings', 'entity': 'regularizing-embeddings', 'name': '${now:%Y-%m-%d_%H-%M-%S}'}, 'training': {'max_epochs': 100, 'patience': 50, 'limit_train_batches': 100, 'limit_val_batches': 100}, 'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'num_workers': 4, 'pin_memory': True}, 'optimizer': {'_target_': 'torch.optim.AdamW', 'lr': 0.0001, 'weight_decay': 0.0001}, 'scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'mode': 'min', 'factor': 0.1, 'patience': 5}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'regularization_lambda': 0.001, 'paths': {'output_dir': 'checkpoints'}}, 'model': {'_target_': 'RegularizingEmbeddings.models.lru.LRUMinimal', 'input_dim': 3, 'd_model': 64, 'd_state': 32, 'mlp_hidden': 64, 'siso': False, 'rmin': 0.8, 'rmax': 0.99, 'dropout': 0.1}, 'data': {'flow': {'_target_': 'RegularizingEmbeddings.dysts_sim.flows.Lorenz', 'random_state': 42, 'dt': 0.0075071279699874946}, 'trajectory_params': {'n_periods': 12, 'method': 'Radau', 'resample': True, 'pts_per_period': 200, 'return_times': True, 'standardize': False, 'noise': 0.0, 'num_ics': 20, 'new_ic_mode': 'reference', 'traj_offset_sd': 0.01, 'verbose': False}, 'postprocessing': {'obs_noise': 0.0, 'dims_to_observe': 'all', 'filter_data': False, 'low_pass': 10, 'high_pass': None}, 'train_test_params': {'seq_length': 25, 'seq_spacing': 1, 'train_percent': 0.7, 'test_percent': 0.1, 'split_by': 'trajectory', 'dtype': 'torch.FloatTensor', 'verbose': True, 'delay_embedding_params': {'observed_indices': 'all', 'n_delays': 1, 'delay_spacing': 1}}}, 'regularization': {'_target_': 'RegularizingEmbeddings.regularization.tangling.TanglingRegularization', 'mode': 'efficient', 'epsilon': 1e-06, 'dt': 0.0075071279699874946, 'normalize': True}, 'logger': 'wandb'}\", 'logger': 'wandb', 'training': {'data': {'__target__': 'src.lightning.data.SequenceDataModule', 'batch_size': 32, 'pin_memory': True, 'num_workers': 4}, 'paths': {'output_dir': 'checkpoints'}, 'wandb': {'name': '2025-08-27_14-20-00', 'entity': 'regularizing-embeddings', 'project': 'regularizing-embeddings'}, 'training': {'patience': 50, 'max_epochs': 100, 'limit_val_batches': 100, 'limit_train_batches': 100}, 'criterion': {'_target_': 'torch.nn.MSELoss'}, 'optimizer': {'lr': 0.0001, '_target_': 'torch.optim.AdamW', 'weight_decay': 0.0001}, 'scheduler': {'mode': 'min', 'factor': 0.1, '_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'patience': 5}, 'regularization_lambda': 0.001}, 'regularization': {'dt': 1e-06, 'mode': 'efficient', 'epsilon': 1e-06, '_target_': 'RegularizingEmbeddings.regularization.tangling.TanglingRegularization', 'normalize': True}}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Set your W&B entity and project\n",
    "entity = \"regularizing-embeddings\"  # replace with your W&B entity\n",
    "project = \"regularizing-embeddings\"  # replace with your W&B project\n",
    "\n",
    "# Initialize the W&B API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Fetch all runs from the project\n",
    "runs = api.runs(f\"{entity}/{project}\")\n",
    "\n",
    "# Print basic info for each run\n",
    "for run in runs:\n",
    "    print(f\"Run ID: {run.id}\")\n",
    "    print(f\"Name: {run.name}\")\n",
    "    print(f\"State: {run.state}\")\n",
    "    print(f\"Created at: {run.created_at}\")\n",
    "    print(f\"Summary: {run.summary}\")\n",
    "    print(f\"Config: {run.config}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44317d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_runtime': 693, '_step': 44, '_timestamp': 1756319493.4411347, '_wandb': {'runtime': 693}, 'epoch': 11, 'train_loss_epoch': 30.13536834716797, 'train_loss_step': 27.638742446899418, 'train_reg_loss_epoch': 24018.33203125, 'train_reg_loss_step': 24073.84765625, 'train_total_loss_epoch': 54.15370178222656, 'train_total_loss_step': 51.71259307861328, 'trainer/global_step': 1149, 'val_loss': 23.804990768432617, 'val_reg_loss': 29594.447265625, 'val_total_loss': 53.399436950683594}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c79128e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reg_emb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
